<html> <head> 

<meta http-equiv="Content-Type" content="text/html"> 
<meta name="description" content="***"> 
<meta name="keywords" content="Rui Wang, Shanghai Jiao Tong Univerisity, Machine Translation, NLP> 
<meta charset="UTF-8">

<title> Rui Wang, Shanghai Jiao Tong Univerisity, Machine Translation, NLP</title>

</head> 

<body>
<table>
<tr><th></th><th></th><th></th>
	
<tr>
<td><img src="image-2_1920x2560.jpeg" width=150 height=200 alt="a photo"></td>	
<td>&nbsp;&nbsp;&nbsp;</td>

<td><h1> Rui Wang </h1>
</p>
<strong>Associate Professor & Ph.D. Advisor </strong></br>
Department of Computer Science and Engineering</br>
Shanghai Jiao Tong University</br>
</br>

Email: wangrui12 (as you know) sjtu.edu.cn
</td>

</table>
<hr>
<h3>Biography</h3>
I am a computational linguist working as an associate professor at Shanghai Jiao Tong University (2021-now). Previously, I worked at the Japan National Institute of Information and Communications Technology (NICT) from 2016 to 2020. I was a joint Ph.D. student at Shanghai Jiao Tong University and Institut des Sciences Cognitives of CNRS from 2012 to 2016. </p> 

Language intelligence is a form of intelligence in which humans (and machines) learn about the outside world by reading natural language, producing highly abstract linguistic thinking; and then understanding, improving, and creating about the outside world. We aim to explore and extend the boundaries of language intelligence in the following areas: <br/>

<i>The mechanism and application of LLM. </i>i><br/>
<i>Language Intelligence for Science: primarily linguistic, psychology, cognitive science, etc.</i>i> <br/>
<i>Machine Translation: I worked on it for over ten years and will never give it up. </i>i><br/>
	
</p>
<font color="red"> </font><br/>

<hr>

<h3> Language Intelligence and Computational Linguistic Lab</h3>
I am always fortunate to work with these brilliant young researchers. (Previously Machine Translation Lab from 2017-2022)<br/>
<font color="red">目前实验室主要由NLP背景的同学为主，我们亦欢迎有心理学、语言学、认知科学等交叉学科背景的同学加入实验室。 由于邮件众多，我无法回复所有的邮件，如有冒犯，请见谅。</font>

<h4>@SJTU</h4>
Ph.D. Students: </p>
Qingyuan Tian (2024-)</br>	
Yang Han (2023-)</br>									
<a class="grey" href="https://alsace08.github.io/cv/index.html">Yiming Wang</a> (2023-)</br>
Xingyu Chen (2022-)</br>
<a class="grey" href="https://zwhe99.github.io/">Zhiwei He</a> (2021-)</br>

</p>
Master Students: </p>

2023-: Ziyin Zhang, Xiaofeng Wang, Lizhen Xu, Sheng Li </br>
2022-: Hongkun Hao, Yiming Ai, Tianxiang Hu, Wenhong Zhu, Tian Xia</br>
2021-: <a class="grey" href="https://ruizgao.github.io/">Ruize Gao</a> (2021-)</br>

</p>
Undergraduate Students: </p>	
2022: Yushen Chen (-->Master Student, SJTU)</br>
2021: Xiaoyi Bao (-->Microsoft), Ruiyi Wang (-->Master Student, LTI, CMU)</br>


<h4>@NICT</h4>
Interns: </p>
<a class="grey" href="http://bcmi.sjtu.edu.cn/home/zhangzs/">Zhuosheng Zhang</a> (Matser Student, SJTU, 2019-2020)</br>
<a class="grey" href="https://scholar.google.com/citations?user=PxC3X3QAAAAJ&hl=zh-CN">Haipeng Sun</a> (Ph.D. Student, HIT, 2018-2020)</br>
<a class="grey" href="https://zzsfornlp.github.io/">Zhisong Zhang</a> (Matser Student, SJTU, 2017-2018)</br>
<a class="grey" href="https://chenkehai.github.io/">Kehai Chen</a> (Ph.D. Student, HIT, 2017-2018)</br>

<hr>

<h3>Recent Publication <a class="grey" href="https://scholar.google.com/citations?user=oTU0v5IAAAAJ&hl">[Google Scholar]</a> <a class="grey" href="https://wangruinlp.github.io/pub.html">[Full Publication]</a> </p></h3>
<i>Note: If you have a technical question about a research paper, it is best to try to get in contact with all of the authors, so the most appropriate person can respond as quickly as possible.</i><br/>

<h4>Preprint</h4>

<a class="grey" href="https://arxiv.org/abs/2306.17820"><i>Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Yiming Wang, Zhuosheng Zhang, and <strong>Rui Wang</strong><br/>


<a class="grey" href="https://arxiv.org/abs/2305.04118"><i>Revisiting Acceptability Judgements: CoLAC - Corpus of Linguistic Acceptability in Chinese</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Hai Hu, Ziyin Zhang, Weifang Huang, Jackie Yan-Ki Lai, Aini Li, Yina Patterson, Jiahui Huang, Peng Zhang, Chien-Jer Charles Lin, <strong>Rui Wang</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/huhailinguist/CoLAC">[Data (soon to appear)]</a><br/>
	
<a class="grey" href="https://arxiv.org/abs/2305.04118"><i>Exploring Human-Like Translation Strategy with Large Language Models</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, <strong>Rui Wang</strong>, Zhaopeng Tu, Shuming Shi, Xing Wang<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/zwhe99/MAPS-mt">[Code]</a><br/>

<a class="grey" href="https://arxiv.org/abs/2305.19118"><i>Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, <strong>Rui Wang</strong>, Yujiu Yang, Zhaopeng Tu, Shuming Shi<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/Skytliang/Multi-Agents-Debate">[Code]</a><br/>


<h4>2023</h4>
	
<a class="grey" href="https://arxiv.org/abs/2305.13034"><i>Nearest Neighbor Machine Translation is Meta-Optimizer on Output Projection Layer</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Ruize Gao, Zhirui Zhang*, Yichao Du, Lemao Liu, and <strong>Rui Wang*</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP-2023</strong>), Singapore, 2023<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/RuizGao/knnmt-meta-optimizer">[Code]</a><br/>

<a class="grey" href="https://arxiv.org/pdf/2310.14523v2.pdf"><i>Rethinking Word-Level Auto-Completion in Computer-Aided Translation</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Xingyu Chen, Lemao Liu*, Guoping Huang, Zhirui Zhang, Mingming Yang, Shuming Shi, and <strong>Rui Wang*</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP-2023</strong>), Singapore, 2023<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/galaxyChen/WLAC-Joint-Training">[Code]</a><br/>

<a class="grey" href="https://arxiv.org/pdf/2310.14971.pdf"><i>Penalty Decoding: Well Suppress the Self-Reinforcement Effect in Open-Ended Text Generation</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Wenhong Zhu, Hongkun Hao, and <strong>Rui Wang*</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP-2023</strong>), Singapore, 2023<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/zwhong714/penalty_decoding">[Code]</a><br/>

<a class="grey" href="https://arxiv.org/pdf/2310.14785.pdf"><i>Vision-Enhanced Semantic Entity Recognition in Document Images via Visually-Asymmetric Consistency Learning</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Hao Wang, Xiahua Chen, and <strong>Rui Wang*</strong> and Chenhui Chu<br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP-2023</strong>), Singapore, 2023<br/>

<a class="grey" href="https://arxiv.org/pdf/2310.14802.pdf"><i>DocTrack: A Visually-Rich Document Dataset Really Aligned with Human Eye Movement for Machine Reading</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Hao Wang, Qingxuan Wang, Yue Li, Changqing Wang, Chenhui Chu, <strong>Rui Wang</strong> <br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 2023 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP-2023-findings</strong>), Singapore, 2023<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/hint-lab/doctrack">[Code and Data (soon to appear)]</a><br/>	

<a class="grey" href="https://link.springer.com/chapter/10.1007/978-3-031-44693-1_32"><i>Imitation Attacks Can Steal More Than You Think from Machine Translation Systems</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Tianxiang Hu, Pei Zhang, Baosong Yang*, Jun Xie and <strong>Rui Wang*</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;CCF International Conference on Natural Language Processing and Chinese Computing(<strong>NLPCC-2023</strong>), Foshan, China, 2023<br/>	       
	
<a class="grey" href="https://aclanthology.org/2023.acl-long.482"><i>Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Yiming Wang, Zhuosheng Zhang, and <strong>Rui Wang*</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 61th Annual Meeting of the Association for Computational Linguistics (<strong>ACL-2023</strong>), Toronto, Canada, 2023<br/>	       
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/Alsace08/SumCoT">[Code and Data]</a><br/>
	
<a class="grey" href="https://aclanthology.org/2023.acl-short.164/"><i>TeCS: A Dataset and Benchmark for Tense Consistency of Machine Translation</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Yiming Ai, Zhiwei He, Kai Yu, and <strong>Rui Wang*</strong><br/>	
&nbsp;&nbsp;&nbsp;&nbsp;The 61th Annual Meeting of the Association for Computational Linguistics (<strong>ACL-2023</strong>), Toronto, Canada, 2023<br/>											       
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/rutilel/TeCS-A-Dataset-and-Benchmark-for-Tense-Consistency">[Code and Data]</a><br/>
		       
<a class="grey" href="https://aclanthology.org/2023.findings-acl.162/"><i>Rethinking Translation Memory Augmented Neural Machine Translation</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Hongkun Hao, Guoping Huang, Lemao Liu*, Zhirui Zhang, Shuming Shi, and <strong>Rui Wang*</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 61th Annual Meeting of the Association for Computational Linguistics (<strong>ACL-2023-Findings</strong>), Toronto, Canada, 2023<br/>	       
	
<a class="grey" href="https://ieeexplore.ieee.org/document/10005816/"><i>Universal Multimodal Representation for Language Understanding</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Zhuosheng Zhang#, Kehai Chen, <strong>Rui Wang#</strong>, Masao Utiyama, Eiichiro Sumita, Zuchao Li, Hai Zhao*<br/>
&nbsp;&nbsp;&nbsp;&nbsp;IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2023<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a class="grey" href="https://github.com/cooelf/UVR-NMT">[Codes]</a><br/>

<hr>	
<h3>Academic Services</h3>
PC Chair: MT Summit 2023 (Research Track)<br/>
Associate Editor: IEICE Transactions on Information and Systems<br/>
Area Chairs: ICML-2023, NeurIPS-2023/2022, ICLR-2024/2023/2022/2021, EMNLP-2022, NAACL-2021, CoNLL-2022/2021, CCL-2019/2018<br/>
Standing Reviewers: CL and TACL <br/>


<hr>
<h3>Shared Tasks</h3>

<a class="grey" href="http://www.statmt.org/wmt22/translation-task.html">WMT-2022</a>: 1st places in Livonian<->English<a href="https://aclanthology.org/2022.wmt-1.18/">[Paper]</a><br/>
<a class="grey" href="">IWSLT-2022</a>: 1st in the Simultaneous Speech Translation task <a href="https://aclanthology.org/2022.iwslt-1.10v2.pdf">[Results]</a><a href="https://aclanthology.org/2022.iwslt-1.16/">[Paper]</a> <br/>
<a class="grey" href="http://www.statmt.org/wmt20/translation-task.html">WMT-2020</a>: 1st in three tasks (English->Chinese, Polish->English, and  German-Upper Sorbian) <a href="http://matrix.statmt.org/matrix/systems_list/1920">[Results]</a><a href="http://www.statmt.org/wmt20/pdf/2020.wmt-1.22.pdf">[Paper]</a> <br/>
<a class="grey" href="http://mrp.nlpl.eu/">CoNLL-2019</a>: 1st in the DM sub-task and the 2nd overall <a href="https://docs.google.com/spreadsheets/d/14s5Y_vM8YZ-g7O88EKnJ85c7HH1EXPQizvH3z0wDo80/edit#gid=0">[Results]</a><a href="https://www.aclweb.org/anthology/K19-2004/">[Paper]</a> <br/>

<a class="grey" href="http://www.statmt.org/wmt19/translation-task.html">WMT-2019</a>: 1st in the only unsupervised MT task (German-Czech) <a class="grey" href="http://matrix.statmt.org/matrix/systems_list/1897">[Results]</a> <a class="grey" href="https://www.aclweb.org/anthology/W19-5330/">[Paper]</a> <br/>
<a class="grey" href="http://lotus.kuee.kyoto-u.ac.jp/WAT/WAT2018/index.html">WAT-2018</a>: 1st places  in Myanmar (Burmese) <- English <a class="grey" href="http://lotus.kuee.kyoto-u.ac.jp/WAT/evaluation/list.php?t=27&o=8">[Results]</a><a class="grey" href="wat.pdf">[Paper]</a><br/>

<a class="grey" href="http://www.statmt.org/wmt18/translation-task.html">WMT-2018</a>: 1st places  in four tasks (English<->Estonian and English<->Finnish) <a class="grey" href="wmt-newstest18-results.pdf">[Results]</a><a class="grey" href="http://www.statmt.org/wmt18/pdf/WMT046.pdf">[Paper]</a> </p>
	
<hr>
	
<h3>Teaching</h3>
<h4>Lecture</h4>
CS3602: Natural Language Processing, 2021-2023<br/>

CS438: Information Extraction, 2021-2023<br/>

CS247: Data Mining, 2021-2022</p>



	
<h4>Tutorial</h4>
<a href="https://wangruinlp.github.io/unmt.html"><i>Advances and Challenges in Unsupervised Neural Machine Translation</i></a>. <br/>
&nbsp;&nbsp;&nbsp;&nbsp;<strong>Rui Wang</strong> and Hai Zhao<br/>
&nbsp;&nbsp;&nbsp;&nbsp;16th conference of the European Chapter of the Association for Computational Linguistics (<strong>EACL-Tutorial</strong>), 2021<br/>

<a href="https://aclanthology.org/2021.emnlp-tutorials.6/"><i>Syntax in End-to-End Natural Language Processing</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Hai Zhao, <strong>Rui Wang</strong>, and Kehai Chen<br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 2021 Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP-Tutorial</strong>), 2021<br/>

<a href="https://wangruinlp.github.io/ccmt.pdf"><i>Domain Adaptation for Neural Machine Translation</i></a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;Chenhui Chu and <strong>Rui Wang</strong><br/>
&nbsp;&nbsp;&nbsp;&nbsp;The 16th China Conference on Machine Translation (<strong>CCMT-Tutorial</strong>), 2019<br/>
&nbsp;&nbsp;&nbsp;&nbsp;<i>--You also refer to our survey paper in <a class="grey" href="https://www.aclweb.org/anthology/C18-1111/"><i>[COLING-2018]</i></a> </i></p>


<hr>
	

</details>
<hr>
</body> 
</html>
