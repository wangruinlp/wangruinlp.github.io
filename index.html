<html> <head> 

<meta http-equiv="Content-Type" content="text/html"> 
<meta name="description" content="***"> 
<meta name="keywords" content="Rui Wang, Machine Translation"> 
<meta charset="UTF-8">

<title> Rui Wang, Machine Translation</title>

</head> 

<body>
	
<h1> 王 瑞 (Wang, Rui) </h1>
</p>
Tenure-track Researcher </p>
<a class="grey" href="http://astrec.nict.go.jp/en/">Advanced Translation Technology Laboratory</a>, <a class="grey" href="http://www.nict.go.jp/en/">NICT</a>, Kyoto, Japan</p>


<hr>

<h3>Short Bio <strong><a class="grey" href="cv.pdf">[Full CV Download]</a></strong></h3>
<blockquote>
Dr. Rui Wang is a computational linguist working as a tenure-track researcher in NICT. His research focuses on machine translation (MT),  a classic task in NLP (or even in AI). His recent interests are traditional linguistic based and cutting-edge machine learning based approaches for MT. He (as the first or the corresponding authors) has published more than 30 MT papers in top-tier NLP/ML/AI conferences and journals, such as ACL, EMNLP, ICLR, AAAI, IJCAI, IEEE/ACM transactions, etc. He has also won several first places in top-tier MT/NLP shared tasks, such as WMT-2018, WMT-2019, CoNLL-2019 etc. He served as the area chair of ICLR-2021.</p> 
</blockquote>



<h3>Memorabilia  <strong><a class="grey" href="pb.html">[Selected Publication]</a></strong> </h3>
<blockquote>
In 2020/06, we (with Zuchao) won the first places in three tasks (English->Chinese, Inuktitut->English, and Polish->English) in WMT-2020 </p>
In 2020/04, three linguistic motivated NMT papers were accpeted by ACL-2020, including  <a class="grey" href="https://www.aclweb.org/anthology/2020.acl-main.324/">[Multi-lingual Unsupervised NMT], <a class="grey" href="https://www.aclweb.org/anthology/2020.acl-main.757/">[Context Gates]</a>, and <a class="grey" href="https://www.aclweb.org/anthology/2020.acl-main.34/">[Content Word]</a></p>
In 2019/12, two machine leanring motivated NMT papers <a class="grey" href="https://openreview.net/forum?id=S1efxTVYDr">[Label Smoothing]</a> (with the full review score) and <a class="grey" href="https://openreview.net/forum?id=Byl8hhNYPS">[Universal Visual NMT]</a> were accepted (both oral) by ICLR-2020.</p>
In 2019/10, we (with Zuchao) won 1st in the DM sub-task and the 2nd overall of CoNLL-2019 <a href="https://docs.google.com/spreadsheets/d/14s5Y_vM8YZ-g7O88EKnJ85c7HH1EXPQizvH3z0wDo80/edit#gid=0">[Results]</a><a href="https://www.aclweb.org/anthology/K19-2004/">[Paper]</a>.</p>
In 2019/05, four linguistic motivated NMT papers were accepted by ACL-2019, including <a class="grey" href="https://www.aclweb.org/anthology/papers/P/P19/P19-1119/">[Unsupervised NMT]</a>, <a class="grey" href="https://www.aclweb.org/anthology/papers/P/P19/P19-1174/">[Reordering]</a>, <a class="grey" href="https://www.aclweb.org/anthology/papers/P/P19/P19-1296/">[Sentence-Level Agreement]</a>, and <a class="grey" href="https://www.aclweb.org/anthology/papers/P/P19/P19-1298/">[Lattice Encoder]</a>. </p>		
In 2019/04, we (with Haipeng, Benjamin, and Kehai) won the first place in WMT-2019 unsupervised MT task (German-Czech) <a class="grey" href="http://matrix.statmt.org/matrix/systems_list/1897">[Results]</a> <a class="grey" href="https://www.aclweb.org/anthology/W19-5330/">[Paper]</a>. </p>
In 2018/05, Benjamin and I won the first places of four tasks (English<->Estonian and English<->Finnish) in WMT-2018 <a class="grey" href="wmt-newstest18-results.pdf">[Results]</a><a class="grey" href="https://www.aclweb.org/anthology/W18-6419/">[Paper]</a>. </p>
In 2017 and 2018, I focused on domain adaptation papers for NMT, including <a class="grey" href="http://www.aclweb.org/anthology/P/P17/P17-2089">[Data Selection]</a> (ACL-2017), <a class="grey" href="http://www.aclweb.org/anthology/D/D17/D17-1155">[Instance Weighting]</a> (EMNLP-2017), <a class="grey" href="https://www.aclweb.org/anthology/papers/P/P18/P18-2048/">[Curriculum Learning]</a> (ACL-2018), <a class="grey" href="https://www.aclweb.org/anthology/C18-1111/">[Summary Survey]</a> (COLING-2018).</p>
From 2013 to 2016, I focused on continuous-space representations for SMT, inlcuding <a class="grey" href="http://www.aclweb.org/anthology/D13-1082">[Monolingual NNLM]</a> (EMNLP-2013), <a class="grey" href="https://www.aclweb.org/anthology/D14-1023/">[Bilingual NNLM]</a> (EMNLP-2014), and <a class="grey" href="https://www.ijcai.org/Proceedings/16/Papers/419.pdf">[Graph-based Word Embedding]</a> (IJCAI-2016).</p>
</blockquote>


<h3>News</h3>
<blockquote>
In 2021, I will serve as an area chair of ICLR-2021.<br/>
From 2020, I will serve in the standing reviewer teams of the <a class="grey" href="https://transacl.org/index.php/tacl/about/editorialTeam">TACL</a> and CL journal.
</blockquote>

<hr> 
A good research paper (similar to figure skating) = a high technical merit + a brilliant presentation. <a class="grey" href="https://en.wikipedia.org/wiki/6.0_system">[6.0 system (reality)]</a> <a class="grey" href="https://en.wikipedia.org/wiki/ISU_Judging_System">[ISU Judging System (ideal)]</a></p>
</body> 
</html>
